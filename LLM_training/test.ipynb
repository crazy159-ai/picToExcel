{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceType":"competition","sourceId":86518,"databundleVersionId":9809560},{"sourceType":"modelInstanceVersion","sourceId":6063,"databundleVersionId":7429216,"modelInstanceId":4684}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:05:52.538290Z","iopub.execute_input":"2025-12-18T13:05:52.538604Z","iopub.status.idle":"2025-12-18T13:05:52.932535Z","shell.execute_reply.started":"2025-12-18T13:05:52.538580Z","shell.execute_reply":"2025-12-18T13:05:52.931595Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/deberta_v3/keras/deberta_v3_extra_small_en/2/config.json\n/kaggle/input/deberta_v3/keras/deberta_v3_extra_small_en/2/tokenizer.json\n/kaggle/input/deberta_v3/keras/deberta_v3_extra_small_en/2/metadata.json\n/kaggle/input/deberta_v3/keras/deberta_v3_extra_small_en/2/model.weights.h5\n/kaggle/input/deberta_v3/keras/deberta_v3_extra_small_en/2/assets/tokenizer/vocabulary.spm\n/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ['KERAS_BACKEND'] = 'jax'\n\nimport keras_nlp\nimport keras\nimport tensorflow as tf\n\nfrom tqdm import tqdm\nimport json\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport plotly.express as px\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:05:52.934125Z","iopub.execute_input":"2025-12-18T13:05:52.934649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(tf.__version__,keras.__version__,keras_nlp.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    preset='deberta_v3_extra_small_en'\n    sequence_length=512\n    epochs = 3\n    batch_size = 16\n    scheduler='cosine'\n    label2name={0:'winner_model_a',1:'winner_model_b',2:'winner_tie'}\n    name2label={v:k for k,v in label2name.items()}\n    class_labels = list(label2name.keys())\n    class_names = list(label2name.values())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"keras.mixed_precision.set_global_policy('mixed_float16')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_PATH='/kaggle/input/llm-classification-finetuning'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(f'{BASE_PATH}/train.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Take the first prompt and its associated response\ndf[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\ndf[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\ndf[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n\n# Label conversion\ndf[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\ndf[\"class_label\"] = df.class_name.map(CFG.name2label)\n\n# Show Sample\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n# Take the first prompt and its associated response\ntest_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\ntest_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\ntest_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n\n\n\n# Show Sample\ntest_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_pairs(row):\n    row[\"encode_fail\"] = False\n    try:\n        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        prompt = \"\"\n        row[\"encode_fail\"] = True\n\n    try:\n        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        response_a = \"\"\n        row[\"encode_fail\"] = True\n\n    try:\n        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        response_b = \"\"\n        row[\"encode_fail\"] = True\n        \n    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # Response from Model A\n                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # Response from Model B\n                     ]\n    return row","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.apply(make_pairs,axis=1)\ndisplay(df.head(2))\n\ntest_df = test_df.apply(make_pairs,axis=1)\ndisplay(test_df.head(2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.encode_fail.value_counts(normalize=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_df = pd.concat([df.model_a, df.model_b])\ncounts = model_df.value_counts().reset_index()\ncounts.columns = ['LLM', 'Count']\n\n# Create a bar plot with custom styling using Plotly\nfig = px.bar(counts, x='LLM', y='Count',\n             title='Distribution of LLMs',\n             color='Count', color_continuous_scale='viridis')\n\nfig.update_layout(xaxis_tickangle=-45)  # Rotate x-axis labels for better readability\n\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"counts = df['class_name'].value_counts().reset_index()\ncounts.columns = ['Winner', 'Win Count']\n\nfig = px.bar(counts, x='Winner', y='Win Count',\n             title='Winner distribution for Train Data',\n             labels={'Winner': 'Winner', 'Win Count': 'Win Count'},\n             color='Winner', color_continuous_scale='viridis')\n\nfig.update_layout(xaxis_title=\"Winner\", yaxis_title=\"Win Count\")\n\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split  # Import package\n\ntrain_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n    preset=CFG.preset, # Name of the model\n    sequence_length=CFG.sequence_length, # Max sequence length, will be padded if shorter\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"outs = preprocessor(df.options.iloc[0])  # Process options for the first row\n\n# Display the shape of each processed output\nfor k, v in outs.items():\n    print(k, \":\", v.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_fn(text, label=None):\n    text = preprocessor(text)  # Preprocess text\n    return (text, label) if label is not None else text  # Return processed text and label if available","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_dataset(texts, labels=None, batch_size=32,\n                  cache=True, shuffle=1024):\n    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # Create slices\n    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n    opt = tf.data.Options()  # Create dataset options\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n        opt.experimental_deterministic = False\n    ds = ds.with_options(opt)  # Set dataset options\n    ds = ds.batch(batch_size, drop_remainder=False)  # Batch dataset\n    ds = ds.prefetch(AUTO)  # Prefetch next batch\n    return ds  # Return the built dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train\ntrain_texts = train_df.options.tolist()  # Extract training texts\ntrain_labels = train_df.class_label.tolist()  # Extract training labels\ntrain_ds = build_dataset(train_texts, train_labels,\n                         batch_size=CFG.batch_size,\n                         shuffle=True)\n\n# Valid\nvalid_texts = valid_df.options.tolist()  # Extract validation texts\nvalid_labels = valid_df.class_label.tolist()  # Extract validation labels\nvalid_ds = build_dataset(valid_texts, valid_labels,\n                         batch_size=CFG.batch_size,\n                         shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\n\ndef get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6\n    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8\n\n    def lrfn(epoch):  # Learning rate update function\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr_cb = get_lr_callback(CFG.batch_size, plot=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n                                          monitor='val_log_loss',\n                                          save_best_only=True,\n                                          save_weights_only=True,\n                                          mode='min')  # Get Model checkpoint callback","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define input layers\ninputs = {\n    \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n    \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n}\n# Create a DebertaV3Classifier backbone\nbackbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n    CFG.preset,\n)\n\n# Compute embeddings for first response: (P + R_A) using backbone\nresponse_a = {k: v[:, 0, :] for k, v in inputs.items()}\nembed_a = backbone(response_a)\n\n# Compute embeddings for second response: (P + R_B), using the same backbone\nresponse_b = {k: v[:, 1, :] for k, v in inputs.items()}\nembed_b = backbone(response_b)\n\n# Compute final output\nembeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])\nembeds = keras.layers.GlobalAveragePooling1D()(embeds)\noutputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)\nmodel = keras.Model(inputs, outputs)\n\n# Compile the model with optimizer, loss, and metrics\nmodel.compile(\n    optimizer=keras.optimizers.Adam(5e-6),\n    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n    metrics=[\n        log_loss,\n        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n    ],\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start training the model\nhistory = model.fit(\n    train_ds,\n    epochs=CFG.epochs,\n    validation_data=valid_ds,\n    callbacks=[lr_cb, ckpt_cb]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_weights('/kaggle/working/best_model.weights.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build test dataset\ntest_texts = test_df.options.tolist()\ntest_ds = build_dataset(test_texts,\n                         batch_size=min(len(test_df), CFG.batch_size),\n                         shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions using the trained model on test data\ntest_preds = model.predict(test_ds, verbose=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub_df = test_df[[\"id\"]].copy()\nsub_df[CFG.class_names] = test_preds.tolist()\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}